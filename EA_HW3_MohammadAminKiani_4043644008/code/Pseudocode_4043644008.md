Algorithm 1: Standard Harmony Search (Single-Objective)

1. Initialize Parameters: HMS, HMCR, PAR, MaxIterations.
2. Initialize HM: Generate HMS random solutions in the candidate space.
3. Evaluate: Calculate fitness f(x) for all solutions in HM.
4. While (t < MaxIterations):
   a. Improvise a new solution x_new = (x_1, x_2,..., x_K):
   For each dimension j = 1 to K:
   If rand(0,1) < HMCR:
   x_j = value from HM[random_index][j]
   If rand(0,1) < PAR:
   x_j = Adjust(x_j) // Small change or neighbor swap
   Else:
   x_j = random_item_from_candidates()
   b. Selection/Update:
   If f(x_new) is better than f(x_worst) in HM:
   Replace x_worst with x_new.
   c. t = t + 1.
5. Return: Best solution in HM.

=====================================================
Algorithm 2: Standard Memetic Algorithm (Single-Objective)

1. Initialize: Create an initial population of size N.
2. Evaluate: Calculate fitness f(x) for each individual.
3. While (Termination Condition not met):
   a. Selection: Choose parents from the current population.
   b. Recombination: Apply Crossover to parents to generate offspring P_off.
   c. Mutation: Apply Mutation to P_off to generate P_mut.
   d. Local Search (The Memetic Step):
   For each individual x in P_mut:
   x_refined = Local_Search_Procedure(x)
   // e.g., greedy swaps to improve fitness
   x = x_refined
   e. Evaluation: Calculate f(x) for the refined individuals.
   f. Survival: Select N individuals for the next generation (e.g., elitism).
4. # Return: Best solution found.

## الگوریتم جستجوی هارمونی (تک‌هدفه)

۱. تنظیم پارامترهای اولیه:

- تعیین اندازه حافظه هارمونی (HMS)
- تعیین HMCR, PAR, bw و سایر پارامترهای مسئله (مانند دامنه متغیرها)
- تعریف تابع هدف برای ارزیابی کیفیت راه‌حل‌ها

۲. مقداردهی اولیه حافظه هارمونی (HM):

- تولید HMS راه‌حل اولیه به صورت تصادفی
- ارزیابی هر راه‌حل و ذخیره در حافظه هارمونی

۳. تکرار فرایند بدست آوردن هارمونی جدید تا زمان ارضای شرط توقف:
الف. **تولید هارمونی جدید**:
برای هر متغیر تصمیم _i_ در بردار راه‌حل: - تولید یک عدد تصادفی یکنواخت در بازه [0,1]. - اگر عدد تصادفی < HMCR:
مقدار _x_i_ را از بین مقادیر قبلی موجود در ستون *i*ام حافظه هارمونی انتخاب کن (انتخاب از HM).
در غیر این صورت:
مقدار _x_i_ را به صورت تصادفی از دامنه معتبر متغیر انتخاب کن. - اگر مقدار _x_i_ از حافظه انتخاب شده بود:
یک عدد تصادفی جدید در [0,1] تولید کن.
اگر این عدد < PAR:
مقدار _x_i_ را با یک تغییر جزئی تنظیم کن (افزایش یا کاهش کوچک حداکثر به اندازه bw).
ب. **ارزیابی هارمونی جدید**:
مقدار تابع هدف را برای بردار تصمیم جدید محاسبه کن.
پ. **به‌روزرسانی حافظه هارمونی**:
اگر شایستگی (کیفیت) هارمونی جدید بهتر از بدترین هارمونی فعلی در HM باشد: - هارمونی جدید را جایگزین بدترین هارمونی در حافظه کن (حافظه را به‌روز کن).
ت. **ادامه حلقه**:
مراحل تولید تا به‌روزرسانی را تا زمانی که شرط پایان (مثلاً تعداد تکرار معین یا رسیدن به بهینگی مطلوب) برآورده شود تکرار کن.

۴. خاتمه الگوریتم:

- به عنوان خروجی، بهترین راه‌حل موجود در حافظه هارمونی (یا مجموعه‌ای از بهترین‌ها) ارائه می‌شود.

---

## الگوریتم ممتیک (تک‌هدفه)

۱. مقداردهی اولیه:

- تعریف نحوه‌ی نمایش راه‌حل (کدگذاری کروموزوم‌ها)
- تنظیم پارامترها (اندازه جمعیت N، نرخ ترکیب pc، نرخ جهش pm و ...)
- تولید جمعیت اولیه شامل N راه‌حل (تصادفی یا با استفاده از دانش مسئله)
- ارزیابی اولیه جمعیت (محاسبه تابع هدف برای هر فرد)

۲. حلقه تکاملی (تا زمانی که شرط توقف برقرار نباشد):
الف. **انتخاب والدین:** - با توجه به مقادیر شایستگی، تعدادی والد از جمعیت جاری انتخاب کن (مثلاً به روش تورنمنت یا چرخ رولت).
ب. **تولید فرزندان با ترکیب:** - والدین انتخاب‌شده را جفت کن و با احتمال pc عملگر ترکیب را روی هر جفت اعمال کن تا کروموزوم‌های فرزند تولید شوند.
پ. **اعمال جهش:** - روی هر کروموزوم فرزند با احتمال pm جهش (تغییر تصادفی کوچک) اعمال کن.
ت. **جستجوی محلی روی فرزندان:** - برای هر فرزند (یا برخی از فرزندان منتخب)، رویه بهبود محلی را اعمال کن تا کروموزوم اندکی بهینه‌تر شود. - ارزیابی مجدد فرزندان پس از جستجوی محلی (محاسبه تابع هدف به‌روز شده).
ث. **تشکیل نسل جدید (جایگزینی):** - ترکیب والدین و فرزندان یا فقط استفاده از فرزندان برای به‌روزرسانی جمعیت:
_ (حالت ساده) نسل جدید = تعداد N فرزند تازه ایجاد‌شده (نسل قبلی کاملاً جایگزین می‌شود).
_ (حالت نخبه‌گرا) چند فرد برتر از نسل قبل + بقیه از بهترین فرزندان = نسل جدید. - در هر صورت، اندازه جمعیت را به N فرد در نسل جدید تنظیم کن.
ج. **بروز‌رسانی بهترین راه‌حل پیدا‌شده (اختیاری):** - اگر لازم است، بهترین فرد فعلی را در جایی ذخیره کن (برای گزارش یا استفاده آتی).

۳. پایان الگوریتم:

- خروجی: بهترین راه‌حل یا مجموعه‌ای از بهترین راه‌حل‌های به‌دست‌آمده طی تکامل.

---

Algorithm HSA_SingleObjective(f, {Di}i=1..N, HMS, HMCR, PAR, bw, MaxIters):

    # ----------------------------
    # 1) Initialize Harmony Memory
    # ----------------------------
    HM = empty list
    for j = 1 to HMS:
        x = empty vector of length N
        for i = 1 to N:
            x[i] = RandomSample(Di)
        x.f = f(x)
        HM.add(x)

    # (Optional) keep HM sorted by quality to speed up best/worst access

    best = HM[ArgBest(HM)]

    # ----------------------------
    # 2) Main improvisation loop
    # ----------------------------
    for iter = 1 to MaxIters:

        # 2.a) Improvise a new harmony x_new
        x_new = empty vector length N

        for i = 1 to N:

            r = Uniform(0, 1)

            if r < HMCR:
                # Memory consideration: pick a value from existing HM for dimension i
                # Option A: pick a random harmony and copy its i-th variable
                h = RandomInteger(1, HMS)
                x_new[i] = HM[h][i]

                # Pitch adjustment with probability PAR
                r2 = Uniform(0, 1)
                if r2 < PAR:
                    x_new[i] = PitchAdjust(x_new[i], Di, bw)

            else:
                # Random consideration: sample from domain
                x_new[i] = RandomSample(Di)

        # 2.b) Evaluate
        x_new.f = f(x_new)

        # 2.c) Update Harmony Memory (replace worst if new is better)
        w = ArgWorst(HM)
        if Better(x_new, HM[w]):
            HM[w] = x_new

        # 2.d) Track best
        b = ArgBest(HM)
        if Better(HM[b], best):
            best = HM[b]

    # ----------------------------
    # 3) Return best solution found
    # ----------------------------
    return best

---

Procedure LocalSearch_HillClimb(x, f, LS_Budget):

    x_best = x
    f_best = f(x_best)

    for step = 1 to LS_Budget:
        x_n = GenerateNeighbor(x_best)     # small move in neighborhood
        f_n = f(x_n)

        if Better( (x_n,f_n), (x_best,f_best) ):
            x_best = x_n
            f_best = f_n

    return x_best with fitness f_best

-

Algorithm MA_SingleObjective(f, PopSize, pc, pm, MaxGens, EliteSize, pLS, LS_Budget):

    # ----------------------------
    # 1) Initialize population
    # ----------------------------
    P = empty list
    for i = 1 to PopSize:
        x = InitializeIndividual()
        x.f = f(x)
        P.add(x)

    best = BestIndividual(P)   # by Better()

    # ----------------------------
    # 2) Evolutionary loop
    # ----------------------------
    for gen = 1 to MaxGens:

        # 2.a) Create next generation
        P_next = empty list

        # --- Elitism: copy top EliteSize individuals
        elites = TopK(P, EliteSize)    # sorted by quality
        P_next.add_all(elites)

        # --- Generate offspring until population is full
        while |P_next| < PopSize:

            # Selection
            p1 = SelectParent(P)
            p2 = SelectParent(P)

            # Crossover
            r = Uniform(0,1)
            if r < pc:
                (c1, c2) = Crossover(p1, p2)
            else:
                c1 = Clone(p1)
                c2 = Clone(p2)

            # Mutation
            c1 = Mutate(c1, pm)
            c2 = Mutate(c2, pm)

            # Local Search (Memetic part)
            r1 = Uniform(0,1)
            if r1 < pLS:
                c1 = LocalSearch(c1, f, LS_Budget)
            else:
                c1.f = f(c1)

            r2 = Uniform(0,1)
            if r2 < pLS:
                c2 = LocalSearch(c2, f, LS_Budget)
            else:
                c2.f = f(c2)

            # Add offspring (respect PopSize)
            if |P_next| < PopSize:
                P_next.add(c1)
            if |P_next| < PopSize:
                P_next.add(c2)

        # 2.b) Replace population
        P = P_next

        # 2.c) Update global best
        current_best = BestIndividual(P)
        if Better(current_best, best):
            best = current_best

        # (Optional) early stopping if no improvement for T generations, etc.

    # ----------------------------
    # 3) Return best found
    # ----------------------------
    return best
